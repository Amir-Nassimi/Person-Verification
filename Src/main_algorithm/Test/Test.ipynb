{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18772a66",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cea203a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T14:09:35.957170200Z",
     "start_time": "2024-03-10T14:09:35.937610700Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a930c205",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T14:09:39.179745900Z",
     "start_time": "2024-03-10T14:09:35.957170200Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import json\n",
    "from PIL import Image\n",
    "from matplotlib import patches\n",
    "import matplotlib.pyplot as plt\n",
    "from person_verification.Src.main_algorithm.Codes.TrackingModule import TrackingSystem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acd9543-f238-4de9-a2ef-97676b78c440",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb89e452",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T14:09:41.527047500Z",
     "start_time": "2024-03-10T14:09:41.236865800Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('person_verification/Datasets/Representation/representations.json', \"rb\") as f:\n",
    "    representations = json.load(f)\n",
    "\n",
    "MyTrackingSystem = TrackingSystem(pose_detection_model_path         = 'person_verification/Models/YOLOs/yolov8s-pose.pt',\n",
    "                                  face_verification_database_path   = False,\n",
    "                                  face_verification_representations = representations,\n",
    "                                  emotion_recognition_flag          = False,\n",
    "                                  emotion_recognition_actions       = ['emotion', 'age', 'gender'],\n",
    "                                  pose_detection_device             = 'gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8a763d",
   "metadata": {},
   "source": [
    "# Image test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc5a15b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T14:09:48.852146900Z",
     "start_time": "2024-03-10T14:09:48.616513900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "__________________________________________________________________________________________\n",
      "True\n",
      "__________________________________________________________________________________________\n",
      "The time is:  0.1575150489807129\n",
      "__________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": "[[{'Face_coordination': (875, 394, 1042, 644),\n   'Face_image': <PIL.Image.Image image mode=RGB size=167x250>,\n   'Body_coordination': (886, 394, 1254, 1068),\n   'Body_image': <PIL.Image.Image image mode=RGB size=368x674>,\n   'ID': 'Nassimi',\n   'Strict_flag': False,\n   'age': None,\n   'gender': None,\n   'emotion': None},\n  {'Face_coordination': (1494, 194, 1573, 312),\n   'Face_image': <PIL.Image.Image image mode=RGB size=79x118>,\n   'Body_coordination': (1405, 194, 1579, 578),\n   'Body_image': <PIL.Image.Image image mode=RGB size=174x384>,\n   'ID': None,\n   'Strict_flag': False,\n   'age': None,\n   'gender': None,\n   'emotion': None},\n  True]]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame        = Image.open('person_verification/Src/main_algorithm/Test/Samples/8.jpg')\n",
    "start        = time.time()\n",
    "result, flag = MyTrackingSystem.track([frame])\n",
    "end          = time.time()\n",
    "print('__________________________________________________________________________________________')\n",
    "print(flag)\n",
    "print('__________________________________________________________________________________________')\n",
    "print('The time is: ', end-start)\n",
    "print('__________________________________________________________________________________________')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bb849d-31e5-4962-8799-ae9b26c912d5",
   "metadata": {},
   "source": [
    "# Video test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1c411f-1f35-4ae5-a592-76ef95cbb83c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-10T14:09:31.378936Z"
    }
   },
   "outputs": [],
   "source": [
    "cam     = cv2.VideoCapture('person_verification/Src/main_algorithm/Test/Nazanin22.mp4')\n",
    "counter = 500\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cam.read()\n",
    "    \n",
    "    if ret:\n",
    "        frame        = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        result, flag = MyTrackingSystem.track([frame])\n",
    "        if flag:\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.imshow(frame)\n",
    "\n",
    "            for person in result[0][:-1]:\n",
    "                x1, y1, x2, y2 = person['Body_coordination']\n",
    "                \n",
    "                rect = patches.Rectangle((x1, y1), (x2-x1), (y2-y1), linewidth=1, edgecolor='r', facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "                ax.text(x1, y1, person['ID'])\n",
    "\n",
    "            plt.savefig('person_verification/Src/main_algorithm/Test/Output images/' + str(counter) + '.jpg', dpi=300)\n",
    "            plt.show()\n",
    "            counter = counter + 1\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f43868-0452-4f55-89ab-16ed3789149c",
   "metadata": {},
   "source": [
    "# Camera test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture()\n",
    "cam.open('rtsp://rtsp:Ashkan321@172.16.60.121/Streaming/channels/102')\n",
    "counter = 1\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cam.read()\n",
    "    \n",
    "    if ret:\n",
    "        frame        = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        fig, ax = plt.subplots(1)\n",
    "        result, flag = MyTrackingSystem.track([frame])\n",
    "        \n",
    "        if flag:\n",
    "            ax.imshow(frame)\n",
    "\n",
    "            for person in result[0][:-1]:\n",
    "                x1, y1, x2, y2 = person['Body_coordination']\n",
    "                \n",
    "                rect = patches.Rectangle((x1, y1), (x2-x1), (y2-y1), linewidth=1, edgecolor='r', facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "                ax.text(x1, y1, person['ID'])\n",
    "\n",
    "        plt.savefig('person_verification/Src/main_algorithm/Test/Output images/' + str(counter) + '.jpg', dpi=300)\n",
    "        plt.show()\n",
    "        counter = counter + 1\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T14:09:31.378936Z",
     "start_time": "2024-03-10T14:09:31.378936Z"
    }
   },
   "id": "d9f8d4cd59ce83dd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture()\n",
    "cam.open('rtsp://rtsp:Ashkan321@172.16.60.121')\n",
    "counter = 1\n",
    "\n",
    "# cv2.namedWindow(\"window\", cv2.WND_PROP_FULLSCREEN)\n",
    "# cv2.setWindowProperty(\"window\",cv2.WND_PROP_FULLSCREEN,cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cam.read()\n",
    "    \n",
    "    if ret:\n",
    "        frame2 = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        result, flag = MyTrackingSystem.track([frame2])\n",
    "        \n",
    "        if flag:\n",
    "            for person in result[0][:-1]:\n",
    "                x1, y1, x2, y2 = person['Body_coordination']\n",
    "        \n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color=(255,0,0), thickness=2)\n",
    "                \n",
    "                if person['ID'] != None:\n",
    "                    cv2.putText(frame, person['ID'] + '\\n' + person['age'] + '\\n' + person['gender'] + '\\n' + person['emotion'], (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 1, 2)\n",
    "                \n",
    "        cv2.imshow('window',frame)\n",
    "\n",
    "\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "          break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-10T14:09:31.378936Z"
    }
   },
   "id": "a50d6d820f89504c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-10T14:09:31.378936Z"
    }
   },
   "id": "4bf621b2978c0c47"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
